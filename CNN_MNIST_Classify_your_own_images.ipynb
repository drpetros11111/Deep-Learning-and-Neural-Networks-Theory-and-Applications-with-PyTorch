{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drpetros11111/Deep-Learning-and-Neural-Networks-Theory-and-Applications-with-PyTorch/blob/main/CNN_MNIST_Classify_your_own_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0tWNkbaMoKZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B1USzjUMoKb"
      },
      "outputs": [],
      "source": [
        "# Specify the Mean and standard deviation of all the pixels in the MNIST dataset. They are precomputed\n",
        "mean_gray = 0.1307\n",
        "stddev_gray = 0.3081\n",
        "\n",
        "#Transform the images to tensors\n",
        "#Normalize a tensor image with mean and standard deviation. Given mean: (M1,...,Mn) and std: (S1,..,Sn)\n",
        "#for n channels, this transform will normalize each channel of the input torch.Tensor\n",
        "#i.e. input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
        "\n",
        "transforms_ori = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((mean_gray,), (stddev_gray,))])\n",
        "\n",
        "transforms_photo = transforms.Compose([transforms.Resize((28,28)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((mean_gray,), (stddev_gray,))])\n",
        "\n",
        "#Load our dataset\n",
        "train_dataset = datasets.MNIST(root = './data',\n",
        "                            train = True,\n",
        "                            transform = transforms_ori,\n",
        "                            download = True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root = './data',\n",
        "                            train = False,\n",
        "                            transform = transforms_ori)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IZViPBDMoKc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "random_image = train_dataset[20][0].numpy() * stddev_gray + mean_gray\n",
        "plt.imshow(random_image.reshape(28, 28), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14TF2H4wMoKc"
      },
      "outputs": [],
      "source": [
        "print(train_dataset[20][1].item())   #Print the corresponding label for the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVuut8tjMoKc"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ISAZphDMoKc"
      },
      "outputs": [],
      "source": [
        "#Make the dataset iterable\n",
        "train_load = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                         batch_size = batch_size,\n",
        "                                         shuffle = True)\n",
        "\n",
        "test_load = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                         batch_size = batch_size,\n",
        "                                         shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXe23vSiMoKd"
      },
      "outputs": [],
      "source": [
        "print('There are {} images in the training set'.format(len(train_dataset)))\n",
        "print('There are {} images in the test set'.format(len(test_dataset)))\n",
        "print('There are {} batches in the train loader'.format(len(train_load)))\n",
        "print('There are {} batches in the testloader'.format(len(test_load)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tII1v5UNMoKd"
      },
      "outputs": [],
      "source": [
        "#Create the model class\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        #Same Padding = [(filter size - 1) / 2] (Same Padding--> input size = output size)\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3,stride=1, padding=1)\n",
        "        #The output size of each of the 8 feature maps is\n",
        "        #[(input_size - filter_size + 2(padding) / stride) +1] --> [(28-3+2(1)/1)+1] = 28 (padding type is same)\n",
        "        #Batch normalization\n",
        "        self.batchnorm1 = nn.BatchNorm2d(8)\n",
        "        #RELU\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        #After max pooling, the output of each feature map is now 28/2 = 14\n",
        "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "        #Output size of each of the 32 feature maps remains 14\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        #After max pooling, the output of each feature map is 14/2 = 7\n",
        "        #Flatten the feature maps. You have 32 feature maps, each of them is of size 7x7 --> 32*7*7 = 1568\n",
        "        self.fc1 = nn.Linear(in_features=1568, out_features=600)\n",
        "        self.droput = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=10)\n",
        "    def forward(self,x):\n",
        "        out = self.cnn1(x)\n",
        "        out = self.batchnorm1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool1(out)\n",
        "        out = self.cnn2(out)\n",
        "        out = self.batchnorm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool2(out)\n",
        "        #Now we have to flatten the output. This is where we apply the feed forward neural network as learned before!\n",
        "        #It will take the shape (batch_size, 1568) = (100, 1568)\n",
        "        out = out.view(-1,1568)\n",
        "        #Then we forward through our fully connected layer\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.droput(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the model class\n",
        "This code defines a Convolutional Neural Network (CNN) class named CNN using PyTorch's nn.Module.\n",
        "\n",
        "This class is designed for image classification, specifically for the MNIST dataset which contains handwritten digits.\n",
        "\n",
        "----\n",
        "---\n",
        "\n",
        "\n",
        "Here's a step-by-step explanation:\n",
        "\n",
        "-------------------------\n",
        "#1. Class Definition:\n",
        "\n",
        "\n",
        "    class CNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(CNN,self).__init__()\n",
        "            # ... (Layer definitions) ...\n",
        "\n",
        "         def forward(self,x):\n",
        "            # ... (Forward pass logic) ...\n",
        "\n",
        "\n",
        "##class CNN(nn.Module):\n",
        "\n",
        "This line defines a class named CNN that inherits from nn.Module, which is the base class for all neural network modules in PyTorch.\n",
        "\n",
        "##def __init__(self):\n",
        "This is the constructor of the class.\n",
        "\n",
        "It initializes the layers of the CNN.\n",
        "\n",
        "##super(CNN,self).__init__():\n",
        "This line calls the constructor of the parent class (nn.Module) to ensure proper initialization.\n",
        "\n",
        "##def forward(self,x):\n",
        "This defines the forward pass of the network, specifying how the input data (x) flows through the layers to produce the output.\n",
        "\n",
        "--------------------------------\n",
        "#2. Layer Definitions (within __init__)\n",
        "\n",
        "Convolutional Layers:\n",
        "\n",
        "    self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3,stride=1, padding=1)\n",
        "\n",
        "    self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "##These lines define two convolutional layers (cnn1 and cnn2).\n",
        "\n",
        "##in_channels:\n",
        "Number of input channels (1 for grayscale images in MNIST).\n",
        "\n",
        "##out_channels:\n",
        "Number of output channels (also called filters).\n",
        "\n",
        "cnn1 produces 8 feature maps, and cnn2 produces 32.\n",
        "\n",
        "##kernel_size:\n",
        "Size of the convolutional kernel (filter) - 3x3 for cnn1 and 5x5 for cnn2.\n",
        "\n",
        "##stride:\n",
        "The step size of the kernel as it moves across the input image.\n",
        "\n",
        "##padding:\n",
        "The amount of padding added to the input to control the output size. 'Same' padding ensures the output size is the same as the input size.\n",
        "\n",
        "-----------------------\n",
        "##Batch Normalization:\n",
        "\n",
        "    self.batchnorm1 = nn.BatchNorm2d(8)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "\n",
        "These layers normalize the activations of the previous convolutional layers, which helps in training the network faster and more stable.\n",
        "\n",
        "The argument (8 or 32) specifies the number of features (channels) to normalize.\n",
        "\n",
        "-----------------------------------\n",
        "##Activation Function (ReLU):\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "This applies the Rectified Linear Unit (ReLU) activation function, which introduces non-linearity to the network.\n",
        "\n",
        "----------------------------------------\n",
        "##Max Pooling:\n",
        "\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "These layers perform max pooling, which reduces the spatial dimensions of the feature maps, downsampling them by a factor of 2 in each dimension.\n",
        "\n",
        "---------------------------\n",
        "##Fully Connected Layers:\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=1568, out_features=600)\n",
        "\n",
        "    self.fc2 = nn.Linear(in_features=600, out_features=10)\n",
        "\n",
        "These are the fully connected layers that perform the final classification.\n",
        "\n",
        "-----------------------------------\n",
        "##fc1\n",
        "takes the flattened output of the convolutional layers (1568 features) and maps it to 600 features.\n",
        "\n",
        "##fc2\n",
        "maps the 600 features to 10 output features, representing the 10 digit classes (0-9).\n",
        "\n",
        "---------------------------------------\n",
        "##Dropout:\n",
        "\n",
        "    self.droput = nn.Dropout(p=0.5)\n",
        "\n",
        "This layer randomly sets a fraction (p=0.5) of the input units to 0 during training, which helps prevent overfitting.\n",
        "\n",
        "----------------------------------\n",
        "---------------------------\n",
        "#3. Forward Pass (within forward)\n",
        "\n",
        "This method defines how the input data flows through the layers:\n",
        "\n",
        "    out = self.cnn1(x)  # Convolution 1\n",
        "    out = self.batchnorm1(out)  # Batch Normalization 1\n",
        "    out = self.relu(out)  # ReLU activation\n",
        "    out = self.maxpool1(out)  # Max Pooling 1\n",
        "  # ... (Similar steps for cnn2, batchnorm2, relu, maxpool2) ...\n",
        "\n",
        "    out = out.view(-1,1568)  # Flatten the output\n",
        "    out = self.fc1(out)  # Fully connected 1\n",
        "    out = self.relu(out)  # ReLU activation\n",
        "    out = self.droput(out)  # Dropout\n",
        "    out = self.fc2(out)  # Fully connected 2 (output layer)\n",
        "  return out\n",
        "\n",
        "-------------------------\n",
        "-------------------------------------------\n",
        "----\n",
        "#In summary\n",
        "This code defines a CNN model with two convolutional layers, batch normalization, ReLU activation, max pooling, two fully connected layers, and dropout.\n",
        "\n",
        "The forward method specifies how data flows through these layers to produce the final output, which is a prediction for the digit class.\n",
        "\n"
      ],
      "metadata": {
        "id": "7UTXoX9nO7jR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ornxqUMoKd"
      },
      "outputs": [],
      "source": [
        "model = CNN()\n",
        "CUDA = torch.cuda.is_available()\n",
        "if CUDA:\n",
        "    model = model.cuda()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8r9Ey_UMoKd"
      },
      "outputs": [],
      "source": [
        "#Understand what's happening\n",
        "iteration = 0\n",
        "correct_nodata = 0\n",
        "correct_data = 0\n",
        "for i,(inputs,labels) in enumerate (train_load):\n",
        "    if iteration==1:\n",
        "        break\n",
        "    inputs = Variable(inputs)\n",
        "    labels = Variable(labels)\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "    print(\"For one iteration, this is what happens:\")\n",
        "    print(\"Input Shape:\",inputs.shape)\n",
        "    print(\"Labels Shape:\",labels.shape)\n",
        "    output = model(inputs)\n",
        "    print(\"Outputs Shape\",output.shape)\n",
        "    _, predicted_nodata = torch.max(output, 1)\n",
        "    print(\"Predicted Shape\",predicted_nodata.shape)\n",
        "    print(\"Predicted Tensor:\")\n",
        "    print(predicted_nodata)\n",
        "    correct_nodata += (predicted_nodata == labels).sum()\n",
        "    print(\"Correct Predictions: \",correct_nodata)\n",
        "    _, predicted_data = torch.max(output.data, 1)\n",
        "    correct_data += (predicted_data == labels.data).sum()\n",
        "    print(\"Correct Predictions:\",correct_data)\n",
        "\n",
        "\n",
        "    iteration += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAwllfXMMoKe"
      },
      "outputs": [],
      "source": [
        "#Training the CNN\n",
        "num_epochs = 2\n",
        "\n",
        "#Define the lists to store the results of loss and accuracy\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "#Training\n",
        "for epoch in range(num_epochs):\n",
        "    #Reset these below variables to 0 at the begining of every epoch\n",
        "    correct = 0\n",
        "    iterations = 0\n",
        "    iter_loss = 0.0\n",
        "\n",
        "    model.train()                   # Put the network into training mode\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_load):\n",
        "\n",
        "        # Convert torch tensor to Variable\n",
        "        inputs = Variable(inputs)\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        # If we have GPU, shift the data to GPU\n",
        "        CUDA = torch.cuda.is_available()\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()            # Clear off the gradient in (w = w - gradient)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        iter_loss += loss.data[0]       # Accumulate the loss\n",
        "        loss.backward()                 # Backpropagation\n",
        "        optimizer.step()                # Update the weights\n",
        "\n",
        "        # Record the correct predictions for training data\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum()\n",
        "        iterations += 1\n",
        "\n",
        "    # Record the training loss\n",
        "    train_loss.append(iter_loss/iterations)\n",
        "    # Record the training accuracy\n",
        "    train_accuracy.append((100 * correct / len(train_dataset)))\n",
        "\n",
        "    #Testing\n",
        "    loss = 0.0\n",
        "    correct = 0\n",
        "    iterations = 0\n",
        "\n",
        "    model.eval()                    # Put the network into evaluation mode\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(test_load):\n",
        "\n",
        "        # Convert torch tensor to Variable\n",
        "        inputs = Variable(inputs)\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        CUDA = torch.cuda.is_available()\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels) # Calculate the loss\n",
        "        loss += loss.data[0]\n",
        "        # Record the correct predictions for training data\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    # Record the Testing loss\n",
        "    test_loss.append(loss/iterations)\n",
        "    # Record the Testing accuracy\n",
        "    test_accuracy.append((100 * correct / len(test_dataset)))\n",
        "\n",
        "    print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}, Testing Loss: {:.3f}, Testing Acc: {:.3f}'\n",
        "           .format(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1],\n",
        "             test_loss[-1], test_accuracy[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tnAabq-MoKe"
      },
      "outputs": [],
      "source": [
        "#Run this if you want to save the model\n",
        "torch.save(model.state_dict(),'CNN_MNIST.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk_qeICGMoKe"
      },
      "outputs": [],
      "source": [
        "# Loss\n",
        "f = plt.figure(figsize=(10, 10))\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(test_loss, label='Testing Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyLbf-RTMoKe"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "f = plt.figure(figsize=(10, 10))\n",
        "plt.plot(train_accuracy, label='Training Accuracy')\n",
        "plt.plot(test_accuracy, label='Testing Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSgBn25UMoKf"
      },
      "outputs": [],
      "source": [
        "#Run this if you want to load the model\n",
        "model.load_state_dict(torch.load('CNN_MNIST.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pohZRycCMoKf"
      },
      "outputs": [],
      "source": [
        "#Predict your own image\n",
        "def predict(img_name,model):\n",
        "    image = cv2.imread(img_name,0)   #Read the image\n",
        "    ret, thresholded = cv2.threshold(image,127,255,cv2.THRESH_BINARY)   #Threshold the image\n",
        "    img = 255-thresholded           #Apply image negative\n",
        "    cv2.imshow('Original',img)      #Display the processed image\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    img = Image.fromarray(img)      #Convert the image to an array\n",
        "    img = transforms_photo(img)     #Apply the transformations\n",
        "    img = img.view(1,1,28,28)       #Add batch size\n",
        "    img = Variable(img)             #Wrap the tensor to a variable\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        img = img.cuda()\n",
        "\n",
        "    output = model(img)\n",
        "    print(output)\n",
        "    print(output.data)\n",
        "    _, predicted = torch.max(output,1)\n",
        "    return  predicted.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGg8Pd7VMoKf"
      },
      "outputs": [],
      "source": [
        "pred = predict('3.jpg', model)\n",
        "print(\"The Predicted Label is {}\".format(pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}