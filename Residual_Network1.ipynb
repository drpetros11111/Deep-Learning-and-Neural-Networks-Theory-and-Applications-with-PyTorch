{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drpetros11111/Deep-Learning-and-Neural-Networks-Theory-and-Applications-with-PyTorch/blob/main/Residual_Network1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKF9DvcZdUQ4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries\n",
        "\n",
        "-----------\n",
        "-------------\n",
        "#1. import torch\n",
        "\n",
        "Purpose:\n",
        "\n",
        "This line imports the core PyTorch library, which provides the fundamental data structures (like tensors) and functions for building and training neural networks.\n",
        "\n",
        "Reasoning:\n",
        "\n",
        "It's the foundation of any PyTorch project, giving you access to essential tools for working with tensors, automatic differentiation, and GPU acceleration.\n",
        "\n",
        "-------------------\n",
        "#2. import torch.nn as nn\n",
        "\n",
        "Purpose:\n",
        "This imports the torch.nn module, which contains a variety of pre-built neural network layers (like convolutional layers, linear layers, activation functions) and tools for creating neural network architectures.\n",
        "\n",
        "The as nn part creates a shorter alias for the module, making it more convenient to use in your code (e.g., nn.Linear instead of torch.nn.Linear).\n",
        "\n",
        "Reasoning:\n",
        "It simplifies the process of defining and building neural networks by providing ready-made components.\n",
        "\n",
        "------------------\n",
        "#3. import torchvision\n",
        "\n",
        "Purpose:\n",
        "This imports the torchvision package, which is part of the PyTorch ecosystem and focuses on computer vision tasks.\n",
        "\n",
        "It provides datasets (like CIFAR-10, ImageNet), model architectures (like ResNet, AlexNet), and image transformations (like resizing, cropping).\n",
        "\n",
        "Reasoning:\n",
        "It's extremely helpful for loading and preprocessing image data, using pre-trained models, and applying common image transformations for computer vision applications.\n",
        "\n",
        "--------------------\n",
        "#4. import torchvision.transforms as transforms\n",
        "\n",
        "Purpose:\n",
        "This imports the torchvision.transforms module, specifically designed for applying transformations to image data.\n",
        "\n",
        "It offers a wide range of transformations, including resizing, cropping, color adjustments, data augmentation techniques, and converting images to tensors.\n",
        "\n",
        "The as transforms part creates a shorter alias for convenience.\n",
        "\n",
        "Reasoning:\n",
        "It's crucial for preparing image data for neural network training by allowing you to easily apply various transformations and data augmentation strategies."
      ],
      "metadata": {
        "id": "SPwC-JY_h9tt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwCLd-nkdUQ8"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 25\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Image preprocessing modules\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "# CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True,\n",
        "                                             transform=transform,\n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                            train=False,\n",
        "                                            transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loaders\n",
        "\n",
        "------------------\n",
        "#1. Device Configuration\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "##Purpose:\n",
        "This line determines whether a CUDA-enabled GPU is available.\n",
        "\n",
        "If so, it sets the device to 'cuda' for GPU acceleration; otherwise, it defaults to 'cpu'.\n",
        "\n",
        "##Reasoning:\n",
        "Utilizing a GPU can significantly speed up the training process, especially for computationally intensive tasks like deep learning.\n",
        "\n",
        "----------------------------\n",
        "#2. Hyperparameters\n",
        "\n",
        "    num_epochs = 25\n",
        "    batch_size = 100\n",
        "    learning_rate = 0.001\n",
        "\n",
        "##Purpose:\n",
        "These lines define hyperparameters for the training process:\n",
        "\n",
        "##num_epochs:\n",
        "The number of times the entire training dataset is iterated over.\n",
        "\n",
        "##batch_size:\n",
        "The number of training samples processed in each iteration.\n",
        "\n",
        "##learning_rate:\n",
        "Controls the step size during optimization, influencing how quickly the model learns.\n",
        "\n",
        "##Reasoning:\n",
        "Hyperparameters are crucial for controlling the training process and achieving optimal model performance.\n",
        "\n",
        "--------------------\n",
        "#3. Image Preprocessing\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "       transforms.Pad(4),\n",
        "       transforms.RandomHorizontalFlip(),\n",
        "       transforms.RandomCrop(32),\n",
        "       transforms.ToTensor()])\n",
        "\n",
        "##Purpose:\n",
        "This code defines a sequence of image transformations using transforms.Compose.\n",
        "\n",
        " These transformations will be applied to the training images.\n",
        "\n",
        "##transforms.Pad(4):\n",
        "Adds padding of 4 pixels on each side of the image.\n",
        "\n",
        "##transforms.RandomHorizontalFlip():\n",
        "Randomly flips the image horizontally.\n",
        "\n",
        "##transforms.RandomCrop(32):\n",
        "Randomly crops a 32x32 section from the image.\n",
        "\n",
        "##transforms.ToTensor():\n",
        "Converts the image to a PyTorch tensor.\n",
        "\n",
        "##Reasoning:\n",
        "These transformations are commonly used for data augmentation, which helps improve the model's generalization ability and prevent overfitting.\n",
        "\n",
        "----------------------\n",
        "#4. CIFAR-10 Dataset and Data Loaders\n",
        "\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             \n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True)\n",
        "\n",
        "    test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                            \n",
        "    train=False,\n",
        "                                            \n",
        "    transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader\n",
        "    (dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader     \n",
        "    (dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "##Purpose:\n",
        "This code loads the CIFAR-10 dataset, which consists of 60,000 32x32 color images in 10 classes.\n",
        "\n",
        "##train_dataset:\n",
        "Loads the training set and applies the defined transformations.\n",
        "\n",
        "##test_dataset:\n",
        "Loads the test set without augmentations.\n",
        "\n",
        "##train_loader and test_loader:\n",
        "Create data loaders to efficiently iterate over the datasets in batches during training and testing.\n",
        "\n",
        "##Reasoning:\n",
        "Data loaders provide a convenient way to access and manage the dataset during training and evaluation.\n",
        "\n",
        "They handle batching, shuffling, and loading data onto the specified device."
      ],
      "metadata": {
        "id": "F6r2bn0mkhWV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHATnAqpdUQ9"
      },
      "source": [
        "![resnetimage](https://user-images.githubusercontent.com/30661597/78585170-f4ac7c80-786b-11ea-8b00-8b751c65f5ca.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is a Residual Network (ResNet)?\n",
        "\n",
        "----------------\n",
        "---------------------\n",
        "\n",
        "A Residual Network (ResNet) is a type of deep convolutional neural network (CNN) architecture that introduces the concept of skip connections or residual connections.\n",
        "\n",
        "These connections allow the network to learn residual functions instead of directly mapping inputs to outputs.\n",
        "\n",
        "-------------------------------\n",
        "#Key Idea behind ResNets:\n",
        "\n",
        "Traditional deep neural networks can suffer from the vanishing gradient problem, where gradients become very small during backpropagation, hindering the training of deeper layers.\n",
        "\n",
        "ResNets address this issue by using skip connections to bypass some layers and directly connect earlier layers to later layers.\n",
        "\n",
        "This allows gradients to flow more easily through the network, enabling the training of much deeper networks.\n",
        "\n",
        "---------------------------\n",
        "#Structure of a Residual Block:\n",
        "\n",
        "The fundamental building block of a ResNet is the residual block.\n",
        "\n",
        "A typical residual block consists of:\n",
        "\n",
        "##Two convolutional layers:\n",
        "These layers perform feature extraction.\n",
        "\n",
        "##Batch normalization:\n",
        "This helps stabilize training and improve performance.\n",
        "\n",
        "##ReLU activation:\n",
        "This introduces non-linearity.\n",
        "\n",
        "##Skip connection:\n",
        "This adds the input of the block to the output, creating a shortcut path for information to flow.\n",
        "\n",
        "--------------------------\n",
        "#Benefits of ResNets:\n",
        "\n",
        "Enable training of very deep networks: ResNets have been successfully used to train networks with hundreds or even thousands of layers.\n",
        "\n",
        "Improved performance: ResNets have achieved state-of-the-art results on various image recognition tasks.\n",
        "\n",
        "Easier optimization: The skip connections help alleviate the vanishing gradient problem, making ResNets easier to train.\n",
        "Applications of ResNets:\n",
        "\n",
        "ResNets have been widely used in various computer vision tasks, including:\n",
        "\n",
        "Image classification\n",
        "Object detection\n",
        "Semantic segmentation\n",
        "Image generation"
      ],
      "metadata": {
        "id": "lu1q7cfErnIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sOaBx-qdUQ-"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the conv3x3 function and the ResidualBlock class:\n",
        "\n",
        "--------------------\n",
        "#1. conv3x3 Function\n",
        "\n",
        "    def conv3x3(in_channels, out_channels, stride=1):\n",
        "        return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "##Purpose:\n",
        "This function creates a 3x3 convolutional layer with the specified input and output channels, stride, and padding.\n",
        "\n",
        "It sets bias=False to disable bias for the convolutional layer.\n",
        "\n",
        "##Reasoning:\n",
        "It provides a convenient way to create a standard 3x3 convolutional layer, commonly used in convolutional neural networks (CNNs).\n",
        "\n",
        "-------------------------\n",
        "#2. ResidualBlock Class\n",
        "\n",
        "    class ResidualBlock(nn.Module):\n",
        "         def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "         super(ResidualBlock, self).__init__()\n",
        "           self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "           self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "           self.relu = nn.ReLU(inplace=True)\n",
        "           self.conv2 = conv3x3(out_channels, out_channels)\n",
        "           self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "           self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "##Purpose:\n",
        "This class defines a residual block, a key building block in ResNet architectures.\n",
        "\n",
        "It consists of two convolutional layers, batch normalization, and ReLU activation.\n",
        "\n",
        " The downsample argument is used to adjust the dimensions of the input if necessary.\n",
        "\n",
        "##Reasoning:\n",
        "Residual blocks allow for training very deep neural networks by introducing skip connections that help alleviate the vanishing gradient problem.\n",
        "\n",
        "----------------------\n",
        "#In summary,\n",
        "the conv3x3 function creates a standard 3x3 convolutional layer, while the ResidualBlock class defines a residual block using two convolutional layers, batch normalization, and ReLU activation.\n",
        "\n",
        "These components are fundamental building blocks for constructing ResNet architectures.\n",
        "\n"
      ],
      "metadata": {
        "id": "EpNZsPTGrE0k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9V4aEhPdUQ_"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                                       nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Resnet Class\n",
        "This class defines the overall architecture of the ResNet model.\n",
        "\n",
        "It utilizes the ResidualBlock we discussed earlier as its building block.\n",
        "\n",
        "--------------------\n",
        "##__init__ method:\n",
        "\n",
        "Initializes the ResNet model with the specified block (which is ResidualBlock in this case), layers (a list specifying the number of residual blocks in each layer), and num_classes (the number of output classes).\n",
        "\n",
        "Sets up the initial convolutional layer (self.conv), batch normalization (self.bn), and ReLU activation (self.relu).\n",
        "\n",
        "Creates three layers (self.layer1, self.layer2, self.layer3) using the make_layer method.\n",
        "\n",
        "Adds an average pooling layer (self.avg_pool) and a fully connected layer (self.fc) for the final classification.\n",
        "make_layer method:\n",
        "\n",
        "This method is responsible for creating a layer of residual blocks.\n",
        "\n",
        "It takes the block type, out_channels, blocks (number of blocks in the layer), and stride as input.\n",
        "\n",
        "If necessary, it creates a downsampling module (downsample) to adjust the dimensions of the input.\n",
        "\n",
        "It then creates a list of residual blocks and returns them as a sequential module.\n",
        "forward method:\n",
        "\n",
        "This method defines the forward pass of the ResNet model.\n",
        "\n",
        "It takes the input tensor x and passes it through the various layers of the network:\n",
        "Initial convolutional layer, batch normalization, and ReLU activation.\n",
        "\n",
        "Three layers of residual blocks.\n",
        "Average pooling layer.\n",
        "\n",
        "Reshaping the output for the fully connected layer.\n",
        "\n",
        "Fully connected layer for classification.\n",
        "Finally, it returns the output of the fully connected layer.\n",
        "\n",
        "---------------------\n",
        "#Detailed Analysis\n",
        "    super(ResNet, self).__init__()\n",
        "##Purpose:\n",
        "This line calls the constructor of the parent class (nn.Module) to properly initialize the ResNet object as a PyTorch module.\n",
        "\n",
        "##Reasoning:\n",
        "It's essential for setting up the underlying infrastructure of the module and ensuring that all the necessary attributes and methods are inherited.\n",
        "\n",
        "    self.in_channels = 16\n",
        "##Purpose:\n",
        "This line initializes the in_channels attribute to 16.\n",
        "\n",
        "This attribute keeps track of the number of input channels for the current layer or block.\n",
        "\n",
        "##Reasoning:\n",
        "It's crucial for defining the input dimensions of subsequent layers and ensuring compatibility between different parts of the network.\n",
        "\n",
        "    self.conv = conv3x3(3, 16)\n",
        "##Purpose:\n",
        "This line creates the initial convolutional layer of the ResNet using the conv3x3 function.\n",
        "\n",
        "It takes 3 input channels (for RGB images) and produces 16 output channels.\n",
        "\n",
        "##Reasoning:\n",
        "The initial convolutional layer is responsible for extracting basic features from the input image.\n",
        "\n",
        "\n",
        "    self.bn = nn.BatchNorm2d(16)\n",
        "##Purpose:\n",
        "This line creates a batch normalization layer (nn.BatchNorm2d) with 16 channels, corresponding to the output channels of the previous convolutional layer.\n",
        "\n",
        "##Reasoning:\n",
        "Batch normalization helps stabilize training and improve performance by normalizing the activations within each batch.\n",
        "\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "##Purpose:\n",
        "This line creates a ReLU activation function (nn.ReLU).\n",
        "\n",
        "The inplace=True argument means that the activation is applied directly to the input tensor, saving memory.\n",
        "\n",
        "##Reasoning:\n",
        "ReLU introduces non-linearity into the network, which is essential for learning complex patterns.\n",
        "\n",
        "    self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "##Purpose:\n",
        "This line creates the first layer of residual blocks using the make_layer method. It passes the block type (ResidualBlock), the desired output channels (16), and the number of blocks in the layer (specified by layers[0]).\n",
        "\n",
        "##Reasoning:\n",
        "This layer further extracts features and introduces skip connections for deeper learning.\n",
        "\n",
        "    self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "##Purpose:\n",
        "Similar to layer1, this line creates the second layer of residual blocks with 32 output channels and a stride of 2.\n",
        "\n",
        "##Reasoning:\n",
        "Increasing the output channels and stride allows the network to learn more complex features at different scales.\n",
        "\n",
        "    self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "##Purpose:\n",
        "This line creates the third layer of residual blocks with 64 output channels and a stride of 2.\n",
        "\n",
        "##Reasoning:\n",
        "This layer further increases the feature complexity and prepares the output for the final classification.\n",
        "\n",
        "    self.avg_pool = nn.AvgPool2d(8)\n",
        "##Purpose:\n",
        "This line creates an average pooling layer (nn.AvgPool2d) with a kernel size of 8.\n",
        "\n",
        "##Reasoning:\n",
        "Average pooling reduces the spatial dimensions of the feature maps, preparing them for the fully connected layer.\n",
        "\n",
        "    self.fc = nn.Linear(64, num_classes)\n",
        "##Purpose:\n",
        "This line creates the fully connected layer (nn.Linear) that maps the final feature representation to the desired number of output classes.\n",
        "\n",
        "##Reasoning:\n",
        "The fully connected layer performs the final classification based on the learned features.\n",
        "----------------\n",
        "#In essence,\n",
        "the ResNet class assembles the different components (convolutional layers, residual blocks, pooling, and fully connected layers) to form the complete ResNet architecture.\n",
        "\n",
        "The forward method defines how data flows through the network during inference or training."
      ],
      "metadata": {
        "id": "p1eiR069zIKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Practice Class Defintion I"
      ],
      "metadata": {
        "id": "Nner3kTd4iB7"
      }
    },
    {
      "source": [
        "class ResNet(nn.Module):\n",
        "       def __init__(self, block, layers, num_classes=10, initial_channels=16):\n",
        "           super(ResNet, self).__init__()\n",
        "           self.in_channels = initial_channels  # Using the parameter\n",
        "           self.conv = conv3x3(3, self.in_channels)  # Referencing the attribute\n",
        "           # ... rest of the code ...\n",
        "\n",
        "   # Creating a ResNet with 32 initial channels:\n",
        "   model = ResNet(ResidualBlock, [2, 2, 2], initial_channels=32)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XsR5zfvc4eRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Practice Class Definition II"
      ],
      "metadata": {
        "id": "VoubKaVu5DXU"
      }
    },
    {
      "source": [
        "class ResNet(nn.Module):\n",
        "       def __init__(self, block, layers, num_classes=10, input_shape=(3, 32, 32)):\n",
        "           super(ResNet, self).__init__()\n",
        "           self.in_channels = input_shape[0] * 2  # Example calculation\n",
        "           # ... rest of the code ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ekQhmGFn5BCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6wbAh12dURA"
      },
      "outputs": [],
      "source": [
        "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
        "\n",
        "##Purpose:\n",
        "This line creates an instance of your ResNet model, transfers it to the specified device (GPU if available, otherwise CPU), and assigns it to the variable model.\n",
        "\n",
        "\n",
        "##ResNet(ResidualBlock, [2, 2, 2]):\n",
        "This part instantiates your ResNet model.\n",
        "\n",
        " You're using the ResidualBlock as the building block for your ResNet, and the list [2, 2, 2] specifies the number of residual blocks in each of the three layers of your ResNet architecture.\n",
        "\n",
        "##Meaning of \"2 Residual Blocks\"\n",
        "\n",
        "In your case, \"2 residual blocks\" in a layer simply means that the layer contains two consecutive instances of the ResidualBlock class.\n",
        "\n",
        "Think of it like this:\n",
        "\n",
        "    Layer 1:\n",
        "       ResidualBlock 1\n",
        "       ResidualBlock 2\n",
        "\n",
        "So, when the input data flows through Layer 1, it will pass through these two ResidualBlocks in sequence.\n",
        "\n",
        "Each ResidualBlock will perform its internal operations (convolution, batch normalization, ReLU, and skip connection) before passing the output to the next ResidualBlock within the layer.\n",
        "\n",
        "Visualizing it\n",
        "\n",
        "You can imagine the structure like this:\n",
        "\n",
        "    Layer 1:\n",
        "       Input --> [ResidualBlock 1] --> [ResidualBlock 2] --> Output of Layer 1\n",
        "\n",
        "The same principle applies to Layer 2 and Layer 3, which also have 2 residual blocks each.\n",
        "\n",
        "Importance of the Number of Blocks\n",
        "\n",
        "The number of residual blocks in each layer influences the depth and complexity of the model.\n",
        "\n",
        " More blocks mean a deeper network capable of learning more intricate patterns. However, increasing the number of blocks also increases the computational cost.\n",
        "\n",
        "Therefore, the choice of the number of residual blocks is a design decision based on the trade-off between model capacity and computational resources.\n",
        "\n",
        "##Balancing Depth and Complexity\n",
        "\n",
        "The choice of the number of residual blocks in each layer of a ResNet is often a design decision based on balancing model depth, complexity, and computational cost.\n",
        "\n",
        "Here's why 2 residual blocks might have been chosen in this case:\n",
        "\n",
        "##Sufficient Depth:\n",
        "Using 2 residual blocks per layer provides a reasonable level of depth to allow the network to learn hierarchical features effectively.\n",
        "\n",
        "Deeper networks can capture more complex patterns in the data, but they can also be more difficult to train and require more resources.\n",
        "\n",
        "##Manageable Complexity:\n",
        "With 2 residual blocks per layer, the overall model complexity is not overly high.\n",
        "\n",
        "This makes the model easier to train and reduces the risk of overfitting, especially when dealing with limited data or computational resources.\n",
        "\n",
        "##Computational Efficiency:\n",
        "Keeping the number of blocks relatively low (like 2) helps maintain a balance between model performance and computational efficiency.\n",
        "\n",
        "Using more blocks would increase the computational cost and training time.\n",
        "Experimentation and Architectural Variations\n",
        "\n",
        "In practice, the number of residual blocks in each layer can be adjusted based on the specific task, dataset size, and available resources.\n",
        "\n",
        "Researchers often experiment with different architectures to find the optimal configuration.\n",
        "\n",
        "For example, some ResNet variants use more blocks in later layers to progressively increase the network's depth and feature extraction capabilities.\n",
        "\n",
        "Others might employ a bottleneck architecture with a narrower middle layer within each residual block to further improve efficiency.\n",
        "\n",
        "In the case of your architecture, using 2 residual blocks per layer appears to be a reasonable starting point that provides a good balance between depth, complexity, and computational considerations.\n",
        "\n",
        "It allows the model to learn effective features without becoming too unwieldy.\n",
        "\n",
        "Ultimately, the best choice for the number of residual blocks depends on the specific context and desired performance characteristics.\n",
        "\n",
        "Experimentation and empirical evaluation are often key to finding the most effective architecture.\n",
        "\n",
        "In summary, \"2 residual blocks\" in a ResNet layer indicates that the layer contains two consecutive ResidualBlock units, contributing to the overall depth and complexity of the network.\n",
        "\n",
        "##.to(device):\n",
        "This is a crucial step.\n",
        "\n",
        "It moves your model to the device you selected earlier (using torch.device).\n",
        "\n",
        "By doing this, you enable GPU acceleration if a CUDA-enabled GPU is available, which can significantly speed up the training process.\n",
        "\n",
        "##model = ...:\n",
        "Finally, the created and device-placed model is assigned to the variable model, which you'll use to interact with your network during training and inference.\n",
        "\n",
        "-----------------------\n",
        "#2. criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "##Purpose:\n",
        "This line defines the loss function you'll use to train your model.\n",
        "\n",
        "    nn.CrossEntropyLoss\n",
        "\n",
        "is a common choice for multi-class classification problems.\n",
        "\n",
        "##Reasoning:\n",
        "The loss function measures the difference between your model's predictions and the actual target labels.\n",
        "\n",
        "It guides the optimization process, helping your model learn to make better predictions by minimizing this difference.\n",
        "\n",
        "--------------------------\n",
        "#3. optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "##Purpose:\n",
        "This line creates an optimizer, which is responsible for updating the model's parameters during training to minimize the loss. You're using the Adam optimizer here.\n",
        "\n",
        "##Reasoning:\n",
        "    torch.optim.Adam:\n",
        "\n",
        "Adam is a popular optimization algorithm known for its efficiency and effectiveness in many deep learning tasks.\n",
        "\n",
        "    model.parameters():\n",
        "This tells the optimizer which parameters of your model it should update during training.\n",
        "\n",
        "##lr=learning_rate:\n",
        "This sets the learning rate, a hyperparameter that controls the step size the optimizer takes when updating the model's parameters.\n",
        "\n",
        "You defined learning_rate earlier in your code."
      ],
      "metadata": {
        "id": "I0-YHSjzoS2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WuaCcsfdURA"
      },
      "outputs": [],
      "source": [
        "decay = 0\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Decay the learning rate every 20 epochs\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        decay+=1\n",
        "        optimizer.param_groups[0]['lr'] = learning_rate * (0.5**decay)\n",
        "        print(\"The new learning rate is {}\".format(optimizer.param_groups[0]['lr']))\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. decay = 0\n",
        "##Purpose:\n",
        "Initializes a variable decay to 0. This variable will be used to control the learning rate decay.\n",
        "\n",
        "##Reasoning:\n",
        "Learning rate decay is a common technique to improve training by gradually reducing the learning rate as training progresses.\n",
        "\n",
        "This helps the model converge to a better solution.\n",
        "\n",
        "------------------\n",
        "##2. model.train()\n",
        "\n",
        "##Purpose:\n",
        "Sets the model to training mode.\n",
        "\n",
        "##Reasoning:\n",
        "This is important because some layers, like dropout and batch normalization, behave differently during training and evaluation.\n",
        "\n",
        "Setting the model to training mode ensures that these layers are activated correctly.\n",
        "\n",
        "------------------\n",
        "##3. for epoch in range(num_epochs):\n",
        "\n",
        "##Purpose:\n",
        "This outer loop iterates over the specified number of epochs (num_epochs).\n",
        "\n",
        "##Reasoning:\n",
        "An epoch represents one complete pass through the entire training dataset.\n",
        "\n",
        "Training for multiple epochs allows the model to learn from the data iteratively.\n",
        "\n",
        "----------\n",
        "#4. if (epoch+1) % 20 == 0:\n",
        "\n",
        "##Purpose:\n",
        "This conditional statement checks if the current epoch number (epoch+1) is divisible by 20.\n",
        "\n",
        "##Reasoning:\n",
        "It's used to implement learning rate decay every 20 epochs.\n",
        "\n",
        "-----------------------\n",
        "#5. decay+=1\n",
        "\n",
        "##Purpose:\n",
        "Increments the decay variable by 1.\n",
        "\n",
        "##Reasoning:\n",
        "This is used to progressively reduce the learning rate as training continues.\n",
        "\n",
        "-----------------------\n",
        "#6. `optimizer.param_groups[0]['lr'] = learning_rate * (0.5decay)`**\n",
        "\n",
        "##Purpose:\n",
        "Updates the learning rate of the optimizer.\n",
        "\n",
        "##Reasoning:\n",
        "It multiplies the initial learning rate (learning_rate) by 0.5 raised to the power of decay.\n",
        "\n",
        "This effectively halves the learning rate every 20 epochs.\n",
        "\n",
        "---------------\n",
        "#7. print(\"The new learning rate is {}\".format(optimizer.param_groups[0]['lr']))\n",
        "\n",
        "##Purpose:\n",
        "Prints the new learning rate to the console.\n",
        "\n",
        "##Reasoning:\n",
        "This helps you monitor the learning rate decay during training.\n",
        "\n",
        "-----------------------\n",
        "#8. for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "##Purpose:\n",
        "This inner loop iterates over the training data in batches.\n",
        "\n",
        "##Reasoning:\n",
        "train_loader is a data loader that provides batches of images and their corresponding labels.\n",
        "\n",
        "--------------------\n",
        "#9.  images = images.to(device)\n",
        "#10. labels = labels.to(device)\n",
        "\n",
        "##Purpose:\n",
        "Moves the images and labels to the specified device (GPU if available, otherwise CPU).\n",
        "\n",
        "##Reasoning:\n",
        "This ensures that the data is processed on the correct device for faster computation.\n",
        "\n",
        "-------------------\n",
        "#11. outputs = model(images)\n",
        "\n",
        "##Purpose:\n",
        "Passes the images through the model to obtain predictions.\n",
        "\n",
        "##Reasoning:\n",
        "This is the forward pass of the model, where it computes the output based on the input images.\n",
        "\n",
        "--------------------\n",
        "#12. loss = criterion(outputs, labels)\n",
        "\n",
        "##Purpose:\n",
        "Calculates the loss between the model's predictions (outputs) and the actual labels (labels) using the specified loss function (criterion).\n",
        "\n",
        "##Reasoning:\n",
        "The loss function quantifies the error made by the model, and the goal of training is to minimize this loss.\n",
        "\n",
        "---------------------\n",
        "#13. optimizer.zero_grad()\n",
        "\n",
        "##Purpose:\n",
        "Resets the gradients of the model's parameters to zero.\n",
        "\n",
        "##Reasoning:\n",
        "This is necessary before computing the gradients for the current batch to avoid accumulating gradients from previous batches.\n",
        "\n",
        "-----------------------\n",
        "#14. loss.backward()\n",
        "\n",
        "##Purpose:\n",
        "Computes the gradients of the loss with respect to the model's parameters.\n",
        "\n",
        "##Reasoning:\n",
        "This is the backpropagation step, where the gradients are calculated to determine how to update the parameters to reduce the loss.\n",
        "\n",
        "-----------------------\n",
        "#15. optimizer.step()\n",
        "\n",
        "##Purpose:\n",
        "Updates the model's parameters based on the computed gradients.\n",
        "\n",
        "##Reasoning:\n",
        "The optimizer uses the gradients to adjust the parameters in a way that minimizes the loss.\n",
        "\n",
        "-------------------------\n",
        "#16. if (i+1) % 100 == 0:\n",
        "\n",
        "##Purpose:\n",
        "This conditional statement checks if the current step number (i+1) is divisible by 100.\n",
        "\n",
        "##Reasoning:\n",
        "It's used to print the training progress every 100 steps.\n",
        "\n",
        "--------------------\n",
        "#17. print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\" .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
        "\n",
        "##Purpose:\n",
        "Prints the current epoch, step, and loss to the console.\n",
        "\n",
        "##Reasoning:\n",
        "This provides feedback on the training progress and helps you monitor the loss over time."
      ],
      "metadata": {
        "id": "IECVRCI_ty8Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnEli98OdURB"
      },
      "outputs": [],
      "source": [
        "#Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. model.eval()\n",
        "\n",
        "##Purpose:\n",
        "Sets the model to evaluation mode.\n",
        "\n",
        "##Reasoning:\n",
        "This is important because some layers, like dropout and batch normalization, behave differently during training and evaluation.\n",
        "\n",
        "Setting the model to evaluation mode ensures that these layers are deactivated or used in their inference mode.\n",
        "\n",
        "----------------------\n",
        "#2. with torch.no_grad():\n",
        "\n",
        "##Purpose:\n",
        "Disables gradient computation.\n",
        "\n",
        "##Reasoning:\n",
        "During evaluation, we don't need to compute gradients since we're not updating the model's parameters.\n",
        "\n",
        "This saves memory and computation time.\n",
        "\n",
        "------------------------\n",
        "#3. correct = 0 4. total = 0\n",
        "\n",
        "##Purpose:\n",
        "Initializes variables to store the number of correct predictions and the total number of samples, respectively.\n",
        "\n",
        "--------------------\n",
        "#5. for images, labels in test_loader:\n",
        "\n",
        "##Purpose:\n",
        "Iterates over the test dataset in batches.\n",
        "\n",
        "##Reasoning:\n",
        "test_loader is a data loader that provides batches of images and their corresponding labels from the test dataset.\n",
        "\n",
        "-------------------\n",
        "#6. images = images.to(device)\n",
        "#7. labels = labels.to(device)\n",
        "\n",
        "##Purpose:\n",
        "Moves the images and labels to the specified device (GPU if available, otherwise CPU).\n",
        "\n",
        "##Reasoning:\n",
        "This ensures that the data is processed on the correct device for faster computation.\n",
        "\n",
        "--------------------------\n",
        "#8. outputs = model(images)\n",
        "\n",
        "##Purpose:\n",
        "Passes the images through the model to obtain predictions.\n",
        "\n",
        "##Reasoning:\n",
        "This is the forward pass of the model, where it computes the output based on the input images.\n",
        "\n",
        "--------------------\n",
        "#9. _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "##Purpose:\n",
        "Gets the predicted class labels.\n",
        "\n",
        "##Reasoning:\n",
        "torch.max finds the index of the maximum value in each row of the outputs.data tensor (which represents the predicted probabilities for each class).\n",
        "\n",
        "The _ is used to discard the actual maximum values, and predicted stores the indices, which correspond to the predicted class labels.\n",
        "\n",
        "------------------\n",
        "#10. total += labels.size(0)\n",
        "\n",
        "##Purpose:\n",
        "Updates the total number of samples processed.\n",
        "\n",
        "##Reasoning:\n",
        "labels.size(0) gives the number of samples in the current batch, which is added to the total count.\n",
        "\n",
        "--------------------------\n",
        "#11. correct += (predicted == labels).sum().item()\n",
        "\n",
        "##Purpose:\n",
        "Updates the number of correct predictions.\n",
        "\n",
        "##Reasoning:\n",
        "(predicted == labels) creates a tensor of Boolean values indicating whether each prediction is correct.\n",
        "\n",
        "sum().item() calculates the total number of correct predictions in the batch and adds it to the correct count.\n",
        "\n",
        "------------------------------\n",
        "#12. print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "##Purpose:\n",
        "Prints the accuracy of the model on the test dataset.\n",
        "\n",
        "#$#Reasoning:\n",
        "\n",
        "It calculates the accuracy as the percentage of correct predictions out of the total number of samples and displays it to the user."
      ],
      "metadata": {
        "id": "z_D4FjjT0PPz"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}